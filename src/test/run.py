import os
import json
from typing import Dict, List, Optional
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage
from music21 import stream, midi, environment


# åˆå§‹åŒ–éŸ³ä¹ç¯å¢ƒ
env = environment.Environment()
env['musicxmlPath'] = '/usr/bin/musescore'
env['musescoreDirectPNGPath'] = '/usr/bin/musescore'
os.environ["GOOGLE_API_KEY"] = "AIzaSyCCjszxRvE87Pep8w5LkikhxnCNOH2aMQY"

class ConductorAgent:
    """æŒ‡æŒ¥å®¶æ ¸å¿ƒä»£ç†"""
    def __init__(self, style: str = "classical", tempo: int = 120, key: str = "C major"):
        self.llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.7)
        self.params = {
            "style": style,
            "tempo": tempo,
            "key": key,
            "structure": {},
            "instruments": []
        }
        self.musicians = {}
        self.score_drafts = {}
        
    def add_instrument(self, instrument_type: str, role: str):
        """æ·»åŠ ä¹å™¨ä»£ç†"""
        instrument_map = {
            "piano": PianistAgent,
            "violin": ViolinistAgent,
            "cello": CellistAgent
        }
        if instrument_type not in instrument_map:
            raise ValueError(f"Unsupported instrument: {instrument_type}")
        self.musicians[instrument_type] = instrument_map[instrument_type](role)
        self.params["instruments"].append(instrument_type)
        
    def design_framework(self) -> Dict:
        """ç”ŸæˆéŸ³ä¹ç»“æ„æ¡†æ¶"""
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", """æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šäº¤å“ä¹æŒ‡æŒ¥å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹å‚æ•°è®¾è®¡éŸ³ä¹ç»“æ„ï¼š
              é£æ ¼ï¼š{style}
              é€Ÿåº¦ï¼š{tempo} BPM
              è°ƒæ€§ï¼š{key}
              åŒ…å«ä¹å™¨ï¼š{instruments}
              è¯·ä»¥JSONæ ¼å¼è¿”å›åŒ…å«ä»¥ä¸‹å­—æ®µçš„ç»“æ„ï¼š
              - form (æ›²å¼ç±»å‹)
              - harmonic_progression (å’Œå£°è¿›è¡Œ)
              - instrumentation_roles (å„ä¹å™¨è§’è‰²)
              - dynamic_plan (åŠ¨æ€å˜åŒ–è®¡åˆ’)""")
        ])
        chain = prompt_template | self.llm
        result = chain.invoke(self.params)
        self.params["structure"] = json.loads(result.content)
        return self.params["structure"]
    
    def generate_part_instructions(self) -> Dict:
        """ç”Ÿæˆå„å£°éƒ¨è¯¦ç»†æŒ‡ä»¤"""
        instructions = {}
        for inst, agent in self.musicians.items():
            role_desc = self.params["structure"]["instrumentation_roles"].get(inst, "")
            prompt = f"""æ ¹æ®æ€»è°±ç»“æ„ç”Ÿæˆ{inst}å£°éƒ¨æŒ‡ä»¤ï¼š
            æ€»ç»“æ„ï¼š{json.dumps(self.params['structure'], ensure_ascii=False)}
            ä¹å™¨è§’è‰²ï¼š{role_desc}
            è¯·åŒ…å«ï¼š
            - ä¸»è¦æ—‹å¾‹å‡ºç°ä½ç½®
            - ä¸å…¶å®ƒå£°éƒ¨çš„é…åˆç‚¹
            - æŠ€æœ¯éš¾ç‚¹æç¤º
            ç”¨JSONæ ¼å¼è¿”å›ï¼š"""
            response = self.llm.invoke(prompt)
            instructions[inst] = json.loads(response.content)
        return instructions
    
    def evaluate_score(self, scores: Dict) -> Dict:
        """ç»“æ„åŒ–ä¹è°±è¯„ä¼°"""
        rubric = {
            "harmonic_consistency": 0.3,
            "dynamic_balance": 0.25,
            "style_compliance": 0.2,
            "technical_feasibility": 0.25
        }
        
        evaluation = {"passed": False, "feedback": []}
        total_score = 0
        
        # å’Œå£°ä¸€è‡´æ€§æ£€æŸ¥
        harmony_check = self.llm.invoke(f"""æ£€æŸ¥ä»¥ä¸‹ä¹è°±çš„å’Œå£°ä¸€è‡´æ€§ï¼š
        {json.dumps(scores)}
        å‚è€ƒå’Œå£°è¿›è¡Œï¼š{self.params['structure']['harmonic_progression']}
        è¿”å›JSONï¼š{{"score":0-1, "issues":[...]}}""")
        harmony_result = json.loads(harmony_check.content)
        total_score += harmony_result["score"] * rubric["harmonic_consistency"]
        evaluation["feedback"].extend(harmony_result["issues"])
        
        # åŠ¨æ€å¹³è¡¡æ£€æŸ¥
        balance_check = self.llm.invoke(f"""åˆ†æå£°éƒ¨åŠ¨æ€å¹³è¡¡ï¼š
        {json.dumps(scores)}
        é¢„æœŸåŠ¨æ€è®¡åˆ’ï¼š{self.params['structure']['dynamic_plan']}
        è¿”å›JSONï¼š{{"score":0-1, "adjustments":[...]}}""")
        balance_result = json.loads(balance_check.content)
        total_score += balance_result["score"] * rubric["dynamic_balance"]
        evaluation["feedback"].extend(balance_result["adjustments"])
        
        evaluation["passed"] = total_score >= 0.75
        return evaluation
    
    def compose(self, output_file: str = "symphony") -> str:
        """å®Œæ•´åˆ›ä½œæµç¨‹"""
        # ç”Ÿæˆç»“æ„æ¡†æ¶
        framework = self.design_framework()
        print(f"ğŸ¼ ç”ŸæˆéŸ³ä¹ç»“æ„ï¼š{framework}")
        
        # ç”Ÿæˆå„å£°éƒ¨æŒ‡ä»¤
        instructions = self.generate_part_instructions()
        
        # å„å£°éƒ¨ç”Ÿæˆä¹è°±
        for inst, agent in self.musicians.items():
            self.score_drafts[inst] = agent.generate_score(
                self.params, 
                instructions[inst]
            )
        
        # å®¡æ ¸ä¸ä¿®æ­£å¾ªç¯
        evaluation = self.evaluate_score(self.score_drafts)
        while not evaluation["passed"]:
            print("âš ï¸ ä¹è°±éœ€è¦ä¿®æ­£ï¼š")
            for feedback in evaluation["feedback"]:
                target_inst = feedback["target"]
                print(f"â†’ {target_inst}: {feedback['message']}")
                revised = self.musicians[target_inst].revise_score(
                    self.params,
                    feedback
                )
                self.score_drafts[target_inst] = revised
            evaluation = self.evaluate_score(self.score_drafts)
        
        # æ··éŸ³è¾“å‡º
        return self._render_audio(output_file)
    
    def _render_audio(self, filename: str) -> str:
        """ç”ŸæˆéŸ³é¢‘æ–‡ä»¶"""
        score = stream.Score()
        for part in self.score_drafts.values():
            score.append(part.to_music21())
        
        # å¯¼å‡ºMIDI
        midi_path = f"{filename}.mid"
        mf = midi.translate.streamToMidiFile(score)
        mf.open(midi_path, 'wb')
        mf.write()
        mf.close()
        
        # è½¬æ¢ä¸ºMP3
        mp3_path = f"{filename}.mp3"
        os.system(f'fluidsynth -ni /usr/share/soundfonts/FluidR3_GM.sf2 {midi_path} -F temp.wav')
        os.system(f'ffmpeg -i temp.wav -acodec libmp3lame {mp3_path}')
        
        return mp3_path

class MusicianAgent:
    """ä¹å™¨ä»£ç†åŸºç±»"""
    
    def __init__(self, role: str):
        self.llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.5)
        self.role = role
        self.part = None
        
    def generate_score(self, global_params: Dict, instruction: Dict) -> 'Part':
        """ç”Ÿæˆä¹è°±ï¼ˆéœ€å­ç±»å®ç°ï¼‰"""
        raise NotImplementedError
        
    def revise_score(self, global_params: Dict, feedback: Dict) -> 'Part':
        """ä¿®æ­£ä¹è°±"""
        prompt = f"""æ ¹æ®æŒ‡æŒ¥å®¶åé¦ˆä¿®æ”¹ä¹è°±ï¼š
        åŸä¹è°±ï¼š{self.part}
        åé¦ˆæ„è§ï¼š{feedback['message']}
        ä¿®æ”¹è¦æ±‚ï¼š{feedback.get('instruction', '')}
        è¯·è¾“å‡ºä¿®è®¢åçš„ä¹è°±ï¼š"""
        revised = self.llm.invoke(prompt)
        return self._parse_score(revised.content)
    
    def _parse_score(self, text: str) -> stream.Part:
        """å°†æ–‡æœ¬ä¹è°±è½¬æ¢ä¸ºmusic21å¯¹è±¡"""
        # ç®€åŒ–çš„ABCè®°è°±æ³•è§£æ
        from music21 import converter
        return converter.parse(text, format='abc')

class CellistAgent(MusicianAgent):
    """å¤§æç´å£°éƒ¨ä»£ç†"""
    
    def generate_score(self, global_params: Dict, instruction: Dict) -> stream.Part:
        prompt = ChatPromptTemplate.from_template("""
        ä½œä¸º{role}æ¼”å¥å®¶ï¼Œè¯·åˆ›ä½œå¤§æç´å£°éƒ¨ï¼š
        - é£æ ¼ï¼š{style}
        - é€Ÿåº¦ï¼š{tempo}BPM
        - è°ƒæ€§ï¼š{key}
        - ç»“æ„æŒ‡ä»¤ï¼š{instruction}
        è¯·ç”¨ABCè®°è°±æ³•è¾“å‡ºåŒ…å«ï¼š
        - ä¸»è¦æ—‹å¾‹æˆ–ä½éŸ³çº¿æ¡
        - æŠ€æœ¯è¦æ±‚ï¼ˆå¦‚æ‹¨å¼¦ã€æ³›éŸ³ç­‰ï¼‰
        """)
        chain = prompt | self.llm
        response = chain.invoke({
            "role": self.role,
            **global_params,
            "instruction": json.dumps(instruction)
        })
        self.part = self._parse_score(response.content)
        return self.part
class PianistAgent(MusicianAgent):
    """é’¢ç´å£°éƒ¨ä»£ç†"""
    
    def generate_score(self, global_params: Dict, instruction: Dict) -> stream.Part:
        prompt = ChatPromptTemplate.from_template("""
        ä½œä¸º{role}æ¼”å¥å®¶ï¼Œè¯·åˆ›ä½œç¬¦åˆä»¥ä¸‹è¦æ±‚çš„é’¢ç´å£°éƒ¨ï¼š
        - é£æ ¼ï¼š{style}
        - é€Ÿåº¦ï¼š{tempo}BPM
        - è°ƒæ€§ï¼š{key}
        - ç»“æ„æŒ‡ä»¤ï¼š{instruction}
        è¯·ç”¨ABCè®°è°±æ³•è¾“å‡ºåŒ…å«ï¼š
        - å³æ‰‹æ—‹å¾‹å£°éƒ¨
        - å·¦æ‰‹ä¼´å¥å£°éƒ¨
        """)
        chain = prompt | self.llm
        response = chain.invoke({
            "role": self.role,
            **global_params,
            "instruction": json.dumps(instruction)
        })
        self.part = self._parse_score(response.content)
        return self.part

class ViolinistAgent(MusicianAgent):
    """å°æç´å£°éƒ¨ä»£ç†"""
    
    def generate_score(self, global_params: Dict, instruction: Dict) -> stream.Part:
        prompt = ChatPromptTemplate.from_template("""
        ä½œä¸º{role}æ¼”å¥å®¶ï¼Œè¯·åˆ›ä½œå°æç´å£°éƒ¨ï¼š
        - ä½¿ç”¨{key}è°ƒæ€§
        - ä¸»è¦æŠ€æœ¯ï¼š{techniques}
        - ç»“æ„è§’è‰²ï¼š{instruction}
        è¾“å‡ºè¦æ±‚ï¼š
        - åŒ…å«å¼“æ³•æ ‡è®°
        - æ ‡æ˜æ‰å¼¦ä½ç½®
        - ABCè®°è°±æ ¼å¼
        """)
        chain = prompt | self.llm
        response = chain.invoke({
            "role": self.role,
            **global_params,
            "techniques": "è¿å¥ä¸è·³å¼“ç»“åˆ",
            "instruction": json.dumps(instruction)
        })
        self.part = self._parse_score(response.content)
        return self.part





# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–æŒ‡æŒ¥å®¶
    conductor = ConductorAgent(
        style="romantic",
        tempo=92,
        key="c minor"
    )
    